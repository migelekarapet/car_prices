{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Prices Model building and tuning\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "\n",
    "import tempfile\n",
    "import subprocess\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.argv[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ot sebyachina\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Mikayel\\\\MK_Organizer\\\\A_interview_2018_Armenia\\\\car_data'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('car_prices_66rows_6_cols_medi.csv')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    'price',\n",
    "    'year',\n",
    "    'symboling',\n",
    "    'make',\n",
    "    'type',\n",
    "    'tuning',    \n",
    "]\n",
    "\n",
    "# We also have to specify dtypes.\n",
    "dtypes = {\n",
    "    'price': np.float32,\n",
    "    'year': np.float32,\n",
    "    'symboling': np.int32,    \n",
    "    'make': str,\n",
    "    'type': str,\n",
    "    'tuning': str,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>symboling</th>\n",
       "      <th>make</th>\n",
       "      <th>type</th>\n",
       "      <th>tuning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9093.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Accord</td>\n",
       "      <td>sedan</td>\n",
       "      <td>advanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8700.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Accord</td>\n",
       "      <td>sedan</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9545.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Accord</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fullyloaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9400.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Accord</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fullyloaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7250.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Civic</td>\n",
       "      <td>compact</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price    year  symboling    make     type       tuning\n",
       "0  9093.0  2008.0          2  Accord    sedan     advanced\n",
       "1  8700.0  2008.0          2  Accord    sedan        basic\n",
       "2  9545.0  2008.0          2  Accord    sedan  fullyloaded\n",
       "3  9400.0  2008.0          2  Accord    sedan  fullyloaded\n",
       "4  7250.0  2008.0          1   Civic  compact        basic"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('car_prices_66rows_6_cols_medi.csv', names=names, dtype=dtypes, na_values=\"?\")\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('car_data_adapted_rel_cand.csv', names=names, dtype=dtypes, na_values=\"?\")\n",
    "data = pd.read_csv('car_prices_66rows_6_cols_medi.csv', names=names, dtype=dtypes, na_values=\"?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_NumericColumn(key='year', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make = tf.feature_column.categorical_column_with_hash_bucket('make', 3)\n",
    "car_make = tf.feature_column.categorical_column_with_vocabulary_list('make',\n",
    "                                                                          vocabulary_list=['Civic', 'Accord','CR-V'])\n",
    "car_type = tf.feature_column.categorical_column_with_vocabulary_list('type',\n",
    "                                                                          vocabulary_list=['sedan', 'compact','suv'])\n",
    "car_tuning = tf.feature_column.categorical_column_with_vocabulary_list('tuning',\n",
    "                                                                           vocabulary_list=['basic', 'advanced','fullyloaded'])\n",
    "\n",
    "le_make = preprocessing.LabelEncoder().fit(data['make'])\n",
    "data['make'] = le_make.transform(data['make'])\n",
    "\n",
    "le_type = preprocessing.LabelEncoder().fit(data['type'])\n",
    "data['type'] = le_type.transform(data['type'])\n",
    "\n",
    "le_tuning = preprocessing.LabelEncoder().fit(data['tuning'])\n",
    "data['tuning'] = le_tuning.transform(data['tuning'])\n",
    "\n",
    "\n",
    "#tf.feature_column.embedding_column(make, 4)\n",
    "tf.feature_column.indicator_column(car_make)\n",
    "tf.feature_column.indicator_column(car_type)\n",
    "tf.feature_column.indicator_column(car_tuning)\n",
    "tf.feature_column.numeric_column('symboling')\n",
    "tf.feature_column.numeric_column('year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of dataset\n",
    "n = data.shape[0]\n",
    "p = data.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data a np.array - converts like\n",
    "# array([[  3,  94,  31],\n",
    "#       [ 29, 170, 115]], dtype=int64)\n",
    "#data_price = data.loc[:, :'price'] \n",
    "\n",
    "data_price = data.loc[:, :'price']\n",
    "data_price = data_price.values / 1000\n",
    "#    data = data.values\n",
    "    \n",
    "# Scale price column\n",
    "#scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#scaler.fit(data_price)\n",
    "#data_price = scaler.transform(data_price)\n",
    "#transform price vector back to df\n",
    "price_df = pd.DataFrame({'price':data_price[:,0]})\n",
    "data.loc[:, :'price'] = price_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, :'price'] = price_df\n",
    "#data.loc[:, :'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data dataframe to np.array vector\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training and test data\n",
    "train_start = 0\n",
    "train_end = int(np.floor(0.8*n))\n",
    "test_start = train_end + 1\n",
    "test_end = n\n",
    "data_train = data[np.arange(train_start, train_end), :]\n",
    "data_test = data[np.arange(test_start, test_end), :]\n",
    "\n",
    "# Build X and y\n",
    "x_train = data_train[:, 1:]\n",
    "y_train = data_train[:, 0]\n",
    "x_test = data_test[:, 1:]\n",
    "y_test = data_test[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  66.85294\n",
      "MSE Test:  257.88403\n",
      "MSE Train:  91.46224\n",
      "MSE Test:  304.35422\n",
      "MSE Train:  10.281862\n",
      "MSE Test:  106.51884\n",
      "MSE Train:  6.166522\n",
      "MSE Test:  62.880917\n",
      "MSE Train:  9.148374\n",
      "MSE Test:  43.321594\n",
      "MSE Train:  11.449583\n",
      "MSE Test:  36.520695\n",
      "MSE Train:  6.0469947\n",
      "MSE Test:  65.78923\n",
      "MSE Train:  8.5991125\n",
      "MSE Test:  97.53682\n",
      "MSE Train:  11.963456\n",
      "MSE Test:  114.39124\n",
      "MSE Train:  10.759615\n",
      "MSE Test:  108.98314\n"
     ]
    }
   ],
   "source": [
    "# Number of features in training data\n",
    "n_features = x_train.shape[1]\n",
    "\n",
    "# Neurons - first layer contains 128 neurons, which is almost the double of the size of the input (66 rows)\n",
    "# next hidden layers are accounting for half of the size of the previous layer: respectively 64, 32 and 16 neurons\n",
    "n_neurons_1 = 128\n",
    "n_neurons_2 = 64\n",
    "n_neurons_3 = 32\n",
    "n_neurons_4 = 16\n",
    "\n",
    "# Session\n",
    "net = tf.InteractiveSession()\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_features])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "# Initializers\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "# Hidden weights\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_features, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "\n",
    "# Output weights -  the second dimension of the previous layer is the first dimension in the current layer for weight matrices\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_4, 1]))\n",
    "\n",
    "# The dimension of the biases = current layer's  weight matrix 2nd dimension\n",
    "#letter  corresponds to the # of neurons in current layer\n",
    "bias_out = tf.Variable(bias_initializer([1]))\n",
    "\n",
    "# Hidden layer - widely used rectified linear unit (ReLU) activation is used here\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "# Output layer (transpose!)\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))\n",
    "\n",
    "# MSE computes the average squared error between predictions and targets (known as cost f-n and is a common method in regression analysis) \n",
    "mse = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "\n",
    "# Optimizer is adapting the weights and biases during optimization. they are using gradient method (usually gradient descent method)\n",
    "# to pinpoint the direction of change for weights and biases in order to minimize MSE (cost f-n). Adam optimizier is kind of a default one\n",
    "opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "\n",
    "# Init\n",
    "net.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "# Fit neural net\n",
    "batch_size = 8\n",
    "mse_train = []\n",
    "mse_test = []\n",
    "\n",
    "# Run\n",
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "\n",
    "    # Shuffle training data\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "    x_train = x_train[shuffle_indices]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "\n",
    "    # Minibatch training\n",
    "    for i in range(0, len(y_train) // batch_size):\n",
    "        start = i * batch_size\n",
    "        batch_x = x_train[start:start + batch_size]\n",
    "        batch_y = y_train[start:start + batch_size]\n",
    "        # Run optimizer with batch\n",
    "        net.run(opt, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "        # Show progress\n",
    "        if np.mod(i, 50) == 0:\n",
    "            # MSE train and test\n",
    "            mse_train.append(net.run(mse, feed_dict={X: x_train, Y: y_train}))\n",
    "            mse_test.append(net.run(mse, feed_dict={X: x_test, Y: y_test}))\n",
    "            print('MSE Train: ', mse_train[-1])\n",
    "            print('MSE Test: ', mse_test[-1])\n",
    "            # Prediction\n",
    "            pred = net.run(out, feed_dict={X: x_test})\n",
    "            #line2.set_ydata(pred)\n",
    "            #plt.title('Epoch ' + str(e) + ', Batch ' + str(i))\n",
    "            #plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8647.751, 8655.655, 8704.563, 8704.563, 8704.563, 8869.4  ,\n",
       "        8820.45 , 8869.4  , 8918.309, 8554.241, 8652.122, 8652.122,\n",
       "        8652.122]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working on finding the root cause for this error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
